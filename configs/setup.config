from functools import partial
from dpipe.train.validator import compute_metrics
from dpipe import commands
from dpipe.split import train_val_test_split
from dpipe.torch import train_step, save_model_state, load_model_state
from dpipe.train import train, TBLogger, TimeProfiler, Checkpoints
from dpipe.commands import lock_dir, populate
from dpipe.layout import Flat
from dpipe.im.utils import identity
from fbp_aug.utils import save_binary_mask


random_state = 42
n_exps = 3
n_splits = 3
batch_size = 32
batches_per_epoch = 100
n_epochs = 100
non_zero_fraction = 0.5

split = train_val_test_split(ids, n_splits=n_splits, val_size=3, random_state=random_state)[:n_exps]

layout = Flat(split)
train_ids = layout.train
val_ids = layout.val
test_ids = layout.test


logger = TBLogger('logs')
run_experiment = (
    lock_dir(),
    architecture.to(device),
    populate('model.pth', lambda: [
        train(
            train_step, batch_iter, n_epochs=n_epochs, logger=logger, time=TimeProfiler(logger.logger),
            checkpoints=Checkpoints('checkpoints', [architecture, optimizer]),
            validate=lambda: compute_metrics(predict, load_x, load_y, val_ids,
                                             val_metrics),
            architecture=architecture, optimizer=optimizer, criterion=criterion
        ),
        save_model_state(architecture, 'model.pth'),
    ]),
    load_model_state(architecture, 'model.pth'),
    populate('test_predictions', commands.predict, test_ids, 'test_predictions', load_x, predict,
             save=save_binary_mask),
    populate(f'test_predictions_{dataset_to_test_name}', commands.predict, ids_to_test,
             f'test_predictions_{dataset_to_test_name}', load_x_to_test, predict,
             save=partial(save_binary_mask, compression=4)),
    commands.evaluate_individual_metrics(identity, metrics, 'test_predictions', 'test_metrics'),
)
